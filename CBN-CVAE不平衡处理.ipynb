{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e23e0070-6512-4290-ae86-0cd0abfcdfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf92185c-dcd7-4851-bd5d-3e5e760360e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集  \n",
    "train_df = pd.read_csv('./数据/KDDTrain+afterP.csv') \n",
    "# train_df = pd.read_csv('../KDDTrain_ADASYN.csv') \n",
    "test_df = pd.read_csv('./数据/KDDTest+afterP.csv')\n",
    "\n",
    "# 划分训练集和测试集的标签和特征\n",
    "y_train = train_df['attack_type']\n",
    "X_train = train_df.drop(columns = ['attack_type'])\n",
    "y_test = test_df['attack_type']\n",
    "X_test = test_df.drop(columns = ['attack_type'])\n",
    "\n",
    "# 需要把类别特征进行数值化：['dos','normal','probe','r2l','u2r']分别映射为0 1 2 3 4\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "# 初始化LabelEncoder  \n",
    "le = LabelEncoder()  \n",
    "  \n",
    "# 对y_train中的类别特征进行数值化  \n",
    "y_train_encoded = le.fit_transform(y_train)  \n",
    "\n",
    "# 对y_test中的类别特征进行数值化  \n",
    "y_test_encoded = le.fit_transform(y_test)  \n",
    "\n",
    "# 将数据转换为PyTorch张量格式,才能进行后续的运算 （需要Numpy格式进行转换）\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)  \n",
    "y_train_encoded = torch.tensor(y_train_encoded, dtype=torch.long)  \n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)  \n",
    "y_test_encoded = torch.tensor(y_test_encoded, dtype=torch.long) \n",
    "\n",
    "# 使用one_hot函数将类别数字转换为独热编码, 条件变分自编码器需要输入标签最好是进行了独热编码  \n",
    "y_train_encoded = F.one_hot(y_train_encoded, num_classes=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6216a2-653d-479d-a323-9e6d2ac199a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7bb33a3-3042-42d0-bcee-7ec9e9bd1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器  \n",
    "train_dataset = TensorDataset(X_train, y_train_encoded)  \n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)  \n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test_encoded)  \n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c51eef-ace7-4d4d-b3f4-b3a336001f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件批量归一化：把数据的类别信息融合到归一化过程中，用类别信息控制缩放（weight）和bias\n",
    "# 公式结合了标准批归一化和类别特定的偏移和缩放，使得归一化过程能够依赖于输入的类别标签\n",
    "class ConditionalBatchNorm(nn.Module):  \n",
    "    def __init__(self, num_features, num_classes):  \n",
    "        super(ConditionalBatchNorm, self).__init__()  \n",
    "        # num_features: 批归一化层需要处理的特征数量。\n",
    "        # num_classes: 类别标签的数量。\n",
    "        self.num_features = num_features  \n",
    "        self.num_classes = num_classes  \n",
    "\n",
    "        # gamma: 全局可学习的缩放因子，大小为num_features。\n",
    "        # beta: 全局可学习的偏移量，初始化为零，大小为num_features。\n",
    "        # weight: 类别特定的缩放因子，大小为num_classes x num_features。\n",
    "        # bias: 类别特定的偏移量，大小为num_classes x num_features。\n",
    "        # 这些都可以通过参数进行学习\n",
    "        self.gamma = nn.Parameter(torch.Tensor(num_features))\n",
    "        #######使用正态分布初始化缩放因子，防止输出过大或者过小\n",
    "        nn.init.normal_(self.gamma, mean=0, std=1)\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))  \n",
    "        self.weight = nn.Parameter(torch.Tensor(num_classes, num_features))  # 这些全都是可以训练的参数 一个表格存储各个类的w和b\n",
    "        self.bias = nn.Parameter(torch.zeros(num_classes, num_features)) \n",
    "        ####### 使用 Xavier Uniform 初始化，防止初始化值异常导致输出异常，出现损失函数异常\n",
    "        nn.init.xavier_uniform_(self.weight)  \n",
    "  \n",
    "    def forward(self, x, y):  \n",
    "        batch_size = x.size(0)  \n",
    "        # 通过y索引相应类别的w和b；重塑w和b与x相同形状\n",
    "        # 使用矩阵乘法实现通过独热编码y选择\n",
    "        y = y.float()\n",
    "        weight = torch.matmul(y, self.weight) \n",
    "        bias = torch.matmul(y, self.bias) \n",
    "        # 沿着批量维度做归一化（减去均值除以方差）\n",
    "        x_mean = x.mean(dim = 0, keepdim=True)\n",
    "        # print(x_mean.shape) 1,feature_dim\n",
    "        x_var = x.var(dim = 0, keepdim=True)\n",
    "        # 特定类别的weight和bias缩放\n",
    "        return self.gamma * (x - x_mean) / torch.sqrt(x_var + 1e-5) + self.beta + weight * x_mean + bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7537cc16-bd79-460c-8de3-7763854e6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Variational Autoencoder模型\n",
    "\n",
    "# 条件变分自编码器：定义，需要输入标签\n",
    "class ConditionalEncoder(nn.Module):  \n",
    "    def __init__(self, input_dim, label_dim, latent_dim, hidden_dim):  \n",
    "        super(ConditionalEncoder, self).__init__()  \n",
    "        self.fc1 = nn.Linear(input_dim + label_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc23 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.bn1 = ConditionalBatchNorm(hidden_dim,label_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc1.bias, 0)\n",
    "        init.kaiming_normal_(self.fc21.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc21.bias, 0)\n",
    "        init.kaiming_normal_(self.fc22.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc22.bias, 0)\n",
    "        init.kaiming_normal_(self.fc23.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc23.bias, 0)\n",
    "        init.kaiming_normal_(self.fc_mean.weight, mode='fan_out', nonlinearity='linear')  \n",
    "        init.constant_(self.fc_mean.bias, 0)  \n",
    "        init.kaiming_normal_(self.fc_log_var.weight, mode='fan_out', nonlinearity='linear')  \n",
    "        init.constant_(self.fc_log_var.bias, 0) \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, labels):  \n",
    "        combined = torch.cat((x, labels), 1)  # 将标签和特征拼接\n",
    "        x = self.fc1(combined)\n",
    "        x = self.bn1(x,labels)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc21(x)\n",
    "        x = self.bn2(x)        \n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc22(x)\n",
    "        x = self.bn1(x,labels)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc23(x)\n",
    "        x = self.bn1(x, labels)\n",
    "        mean = self.fc_mean(x)  \n",
    "        log_var = self.fc_log_var(x)  \n",
    "        return mean, log_var  \n",
    "    \n",
    "    \n",
    "    \n",
    "class ConditionalDecoder(nn.Module):  \n",
    "    def __init__(self, latent_dim, label_dim, output_dim, hidden_dim):  \n",
    "        super(ConditionalDecoder, self).__init__()  \n",
    "        self.fc1 = nn.Linear(latent_dim + label_dim, hidden_dim) \n",
    "        self.fc21 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.fc23 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.bn1 = ConditionalBatchNorm(hidden_dim,label_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)  \n",
    "        init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc1.bias, 0)\n",
    "        init.kaiming_normal_(self.fc21.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc21.bias, 0)\n",
    "        init.kaiming_normal_(self.fc22.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc22.bias, 0)\n",
    "        init.kaiming_normal_(self.fc23.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.constant_(self.fc23.bias, 0)\n",
    "  \n",
    "    def forward(self, z, labels):  \n",
    "        combined = torch.cat((z, labels), 1)  # 把隐藏和标签拼接\n",
    "        x = self.fc1(combined)  \n",
    "        x = self.bn1(x, labels)  \n",
    "        x = F.leaky_relu(x)  \n",
    "        x = self.fc21(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc22(x)\n",
    "        x = self.bn1(x, labels)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc23(x)\n",
    "        x = self.bn1(x, labels)\n",
    "        x = self.fc3(x)  \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f71fc1-73c4-42bd-9fee-6bf1cd02acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbn = ConditionalBatchNorm(60,label_dim)\n",
    "# x = torch.randn(1,60)\n",
    "# labels = torch.randn(1,5)\n",
    "# flops, params = profile(cbn, inputs=(x,labels))\n",
    "# flops, params = clever_format([flops, params], '%.1f')\n",
    "\n",
    "# print('Network Parameters：',params)\n",
    "# print('FLOPs per sample：',flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859ca4cd-d218-45dc-96d8-90b106ee6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件变分自编码器\n",
    "class CVAE(nn.Module):  \n",
    "    def __init__(self, input_dim, latent_dim, label_dim, hidden_dim):  \n",
    "        super(CVAE, self).__init__()  \n",
    "        self.encoder = ConditionalEncoder(input_dim, label_dim, latent_dim, hidden_dim)  \n",
    "        self.decoder = ConditionalDecoder(latent_dim, label_dim, input_dim, hidden_dim)  \n",
    "  \n",
    "    def forward(self, x, labels):  \n",
    "        mean, log_var = self.encoder(x, labels)  \n",
    "        z = self.sample_latent(mean, log_var)  \n",
    "        x_recon = self.decoder(z, labels)  \n",
    "        return x_recon, mean, log_var  \n",
    "  \n",
    "    def sample_latent(self, mean, log_var):  \n",
    "        epsilon = torch.randn_like(mean)  \n",
    "        return mean + torch.exp(0.5 * log_var) * epsilon  \n",
    "\n",
    "# 定义VAE模型和优化器\n",
    "hidden_dim = 60\n",
    "input_dim =  123\n",
    "latent_dim = 32 # 隐变量维度  \n",
    "label_dim = 5 # 标签维度（进行了独热编码）\n",
    "  \n",
    "# 定义CVAE模型和优化器  \n",
    "cvae = CVAE(input_dim, latent_dim, label_dim, hidden_dim)  \n",
    "\n",
    "# 定义CVAE损失函数\n",
    "def cvae_loss(x, x_recon, mean, log_var, y):\n",
    "    # 计算重构损失\n",
    "    # 既然x重构是通过y和隐藏z计算出来的，那重构损失就已经包含了类比信息了\n",
    "    recon_loss = F.mse_loss(x_recon, x, reduction='sum')\n",
    "    # 计算KL散度\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    # 考虑条件信息的重构损失\n",
    "    # conditional_loss = F.cross_entropy(y, x_recon)\n",
    "    # 总损失\n",
    "    total_loss = recon_loss + kl_divergence\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5abc78-d557-4d5a-ac9b-d8856a04b9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "Network Parameters： 22.744K\n",
      "FLOPs per sample： 22.560K\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "from thop import clever_format\n",
    "x = torch.randn(1,123)\n",
    "labels = torch.randn(1,5)\n",
    "flops, params = profile(cvae.encoder, inputs=(x,labels))\n",
    "flops, params = clever_format([flops, params], '%.3f')\n",
    "\n",
    "print('Network Parameters：',params)\n",
    "print('FLOPs per sample：',flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227b0c56-48ec-421f-bf6e-c856279c31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cvae.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041ac43a-1d72-4255-bc35-94594b0a4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 检查是否有GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 将模型移动到GPU上\n",
    "cvae = cvae.to(device)\n",
    "# 将数据移动到GPU上\n",
    "X_train = X_train.to(device)\n",
    "y_train_encoded = y_train_encoded.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test_encoded = y_test_encoded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f99e9d33-1679-4444-9e3f-4ff5e7a1a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder model parameters have been loaded from newcvae_model_para_cbn_120.pth\n"
     ]
    }
   ],
   "source": [
    "#############加载模型\n",
    "# 选择一个加载模型参数的文件路径  \n",
    "load_path ='newcvae_model_para_cbn_100.pth'  \n",
    "# 使用 torch.load() 函数加载模型参数  \n",
    "loaded_parameters = torch.load(load_path)  \n",
    "# 加载模型参数到模型中  \n",
    "cvae.load_state_dict(loaded_parameters)   \n",
    "# 打印加载成功的消息  \n",
    "print(f\"AutoEncoder model parameters have been loaded from {load_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1d31f36e-2ae2-4140-af61-bf87145d0aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 90876431662511.1094\n",
      "Epoch [2/20], Loss: 50742423482288.9062\n",
      "Epoch [3/20], Loss: 50741959937335.5625\n",
      "Epoch [4/20], Loss: 50728897495560.1953\n",
      "Epoch [5/20], Loss: 50615217514560.2891\n",
      "Epoch [6/20], Loss: 50630132849350.8438\n",
      "Epoch [7/20], Loss: 50607756862758.9453\n",
      "Epoch [8/20], Loss: 50748685567006.2891\n",
      "Epoch [9/20], Loss: 50629530390447.9844\n",
      "Epoch [10/20], Loss: 50577263103877.2891\n",
      "Epoch [11/20], Loss: 50559698770831.1250\n",
      "Epoch [12/20], Loss: 50516246738038.1953\n",
      "Epoch [13/20], Loss: 50489963836058.1016\n",
      "Epoch [14/20], Loss: 50363764157277.7422\n",
      "Epoch [15/20], Loss: 50590268250981.8516\n",
      "Epoch [16/20], Loss: 50406724756417.4688\n",
      "Epoch [17/20], Loss: 50154959613598.1328\n",
      "Epoch [18/20], Loss: 50096604365851.1797\n",
      "Epoch [19/20], Loss: 50032378578137.8750\n",
      "Epoch [20/20], Loss: 50190733167939.7500\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 20\n",
    "\n",
    "# 全加了batchNorm之后重构的x和loss就不是nan\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    cvae.train()  # 设置模型为训练模式  \n",
    "    train_loss = 0  # 初始化训练损失  \n",
    "    for i,batch in enumerate(train_loader):  \n",
    "        # 获取批次数据  \n",
    "        data, labels = batch\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        x_recon, mean, log_var = cvae(data,labels)\n",
    "        # print(x_recon)\n",
    "        # print(x_recon.shape)\n",
    "        # 计算损失\n",
    "        loss = cvae_loss(data, x_recon, mean, log_var, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新权重  \n",
    "        optimizer.step()   \n",
    "        # 累加损失以便后续打印平均损失  \n",
    "        train_loss += loss.item()  \n",
    "        # if(i+1)%500 == 0:\n",
    "        #     print(f'i [{i+1}], Loss: {loss.item():.4f}') \n",
    "    scheduler.step()\n",
    "    # 打印每个epoch的平均损失  \n",
    "    train_loss /= len(train_loader.dataset)  \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a7a0a5b7-6b18-458d-ac77-b8f06c59f859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvae model parameters have been saved to newcvae_model_para_cbn_100.pth\n"
     ]
    }
   ],
   "source": [
    "# 假设 CVAE 已经被训练好了  \n",
    "# 获取模型参数  \n",
    "cvae_model_parameters = cvae.state_dict()  \n",
    "# 选择一个保存模型参数的文件路径  \n",
    "save_path = 'newcvae_model_para_cbn_100.pth'  \n",
    "# 使用 torch.save() 函数保存模型参数  \n",
    "torch.save(cvae_model_parameters, save_path)  \n",
    "# 打印保存成功的消息  \n",
    "print(f\"cvae model parameters have been saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "43363483-7b9f-4052-9ef3-77698a2203e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 123])\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "# 通过cvae可以指定类别生成新数据：与训练所用数据相似但不相同  \n",
    "def generate_new_data(cvae,target_category, latent_dim, num_samples = 1):  \n",
    "    cvae.eval()\n",
    "    # 准备目标类别的独热编码y  \n",
    "    # target_category = 2  #（索引从0开始） \n",
    "    num_classes = 5\n",
    "    y_onehot = torch.zeros(num_samples, num_classes)  # num_classes是类别的总数  \n",
    "    y_onehot[:, target_category] = 1  # 设置每一个样本目标类别的位置为1  \n",
    "    y_onehot = y_onehot.to(device)\n",
    "    # 从标准正态分布中随机采样隐变量  \n",
    "    z = Normal(0, 1).sample((num_samples, latent_dim))  \n",
    "    z = z.to(device)\n",
    "    # 使用解码器生成数据  \n",
    "    with torch.no_grad():  \n",
    "        # 解码隐变量和标签以生成数据  \n",
    "        generated_data = cvae.decoder(z, y_onehot)  \n",
    "  \n",
    "    return generated_data\n",
    "  \n",
    "# 设置要生成的数据数量  \n",
    "num_samples = 10  \n",
    "target_category = 0\n",
    "# 生成新数据  \n",
    "new_data = generate_new_data(cvae, target_category, latent_dim, num_samples)  \n",
    "  \n",
    "# 打印生成的数据的形状  \n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fd4616fa-62b9-44f6-9353-c055211b3ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  362.7616, 66005.1328, 19819.4531,  ...,    84.0847, -1418.9258,\n",
      "             0.0000],\n",
      "        [  362.5180, 66009.0156, 19838.7891,  ...,    84.0353, -1418.9094,\n",
      "             0.0000],\n",
      "        [  362.9855, 66002.9297, 19807.8945,  ...,    84.1126, -1418.9357,\n",
      "             0.0000],\n",
      "        ...,\n",
      "        [  362.8918, 66002.5156, 19806.6387,  ...,    84.1174, -1418.9368,\n",
      "             0.0000],\n",
      "        [  362.3427, 66012.6484, 19856.4512,  ...,    83.9867, -1418.8964,\n",
      "             0.0000],\n",
      "        [  362.3982, 66009.4531, 19841.8340,  ...,    84.0362, -1418.9056,\n",
      "             0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 分别生成 DOS 0类型样本 21416 个，Probe 2类型样本55687 个\n",
    "# R2L 3类型样本 66348，U2R 4类型样本 67291 个\n",
    "# 生成的样本与原样本混合，形成 VAE 过采样后的训练集，使得每种类别样本的数量都为 67343个。\n",
    "# 设置要生成的数据数量  \n",
    "num_samples = 21416  \n",
    "target_category = 0\n",
    "# 生成新数据  \n",
    "new_data_dos = generate_new_data(cvae, target_category, latent_dim, num_samples)  \n",
    "\n",
    "#生成标签的一维Tensor\n",
    "labels = torch.full((num_samples,), target_category, dtype=torch.long)    \n",
    "labels = labels.view(num_samples, 1)  \n",
    "labels = labels.to(device)\n",
    "# 可以沿着最后一个维度拼接数据和标签  \n",
    "new_data_dos = torch.cat((new_data_dos, labels), dim=-1)  \n",
    "  \n",
    "# 输出结果以验证  \n",
    "print(new_data_dos)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01eba08-43aa-49a3-84be-dd5493391351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d75e39ff-60fc-4801-bff3-8c2411e5857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.1738e+02,  8.8684e+05,  3.0966e+06,  ..., -8.6188e+01,\n",
      "         -8.9344e+02,  2.0000e+00],\n",
      "        [ 8.1725e+02,  8.8684e+05,  3.0965e+06,  ..., -8.6168e+01,\n",
      "         -8.9345e+02,  2.0000e+00],\n",
      "        [ 8.1738e+02,  8.8684e+05,  3.0965e+06,  ..., -8.6175e+01,\n",
      "         -8.9345e+02,  2.0000e+00],\n",
      "        ...,\n",
      "        [ 8.1753e+02,  8.8684e+05,  3.0965e+06,  ..., -8.6148e+01,\n",
      "         -8.9345e+02,  2.0000e+00],\n",
      "        [ 8.1485e+02,  8.8688e+05,  3.0968e+06,  ..., -8.6856e+01,\n",
      "         -8.9329e+02,  2.0000e+00],\n",
      "        [ 8.1742e+02,  8.8684e+05,  3.0966e+06,  ..., -8.6198e+01,\n",
      "         -8.9344e+02,  2.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 设置要生成的数据数量  \n",
    "num_samples = 55687  \n",
    "target_category = 2\n",
    "# 生成新数据  \n",
    "new_data_probe = generate_new_data(cvae, target_category, latent_dim, num_samples)  \n",
    "\n",
    "#生成标签的一维Tensor\n",
    "labels = torch.full((num_samples,), target_category, dtype=torch.long)  \n",
    "# 为了拼接将标签Tensor扩展到与数据Tensor相同的维度  \n",
    "labels = labels.view(num_samples, 1)  \n",
    "labels = labels.to(device)\n",
    "# 沿着最后一个维度拼接数据和标签  \n",
    "new_data_probe = torch.cat((new_data_probe, labels), dim=-1)  \n",
    "  \n",
    "# 输出结果以验证  \n",
    "print(new_data_probe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "98048ce4-3b53-49cc-8798-891a1bc2822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2041e+02,  1.3076e+04,  9.4091e+03,  ...,  1.2300e+00,\n",
      "         -2.5358e+02,  3.0000e+00],\n",
      "        [-1.2200e+02,  1.3107e+04,  9.5609e+03,  ...,  8.1371e-01,\n",
      "         -2.5345e+02,  3.0000e+00],\n",
      "        [-1.2087e+02,  1.3084e+04,  9.4499e+03,  ...,  1.1235e+00,\n",
      "         -2.5354e+02,  3.0000e+00],\n",
      "        ...,\n",
      "        [-1.2124e+02,  1.3091e+04,  9.4851e+03,  ...,  1.0273e+00,\n",
      "         -2.5351e+02,  3.0000e+00],\n",
      "        [-1.2111e+02,  1.3089e+04,  9.4726e+03,  ...,  1.0608e+00,\n",
      "         -2.5352e+02,  3.0000e+00],\n",
      "        [-1.2119e+02,  1.3091e+04,  9.4821e+03,  ...,  1.0316e+00,\n",
      "         -2.5352e+02,  3.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 设置要生成的数据数量  \n",
    "num_samples = 66348  \n",
    "target_category = 3\n",
    "# 生成新数据  \n",
    "new_data_r2l = generate_new_data(cvae, target_category, latent_dim, num_samples)  \n",
    "\n",
    "#生成标签的一维Tensor\n",
    "labels = torch.full((num_samples,), target_category, dtype=torch.long)  \n",
    "# 为了拼接将标签Tensor扩展到与数据Tensor相同的维度  \n",
    "labels = labels.view(num_samples, 1)  \n",
    "labels = labels.to(device)\n",
    "# 沿着最后一个维度拼接数据和标签  \n",
    "new_data_r2l = torch.cat((new_data_r2l, labels), dim=-1)  \n",
    "  \n",
    "# 输出结果以验证  \n",
    "print(new_data_r2l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "0517b412-6ac6-448a-95da-a0df7baf557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67291, 123])\n",
      "tensor([[ 1.7178e+03,  1.2175e+03, -7.4007e+04,  ...,  2.0418e+02,\n",
      "         -7.9522e+02,  4.0000e+00],\n",
      "        [ 1.7175e+03,  1.2241e+03, -7.3974e+04,  ...,  2.0408e+02,\n",
      "         -7.9519e+02,  4.0000e+00],\n",
      "        [ 1.7177e+03,  1.2195e+03, -7.3998e+04,  ...,  2.0415e+02,\n",
      "         -7.9521e+02,  4.0000e+00],\n",
      "        ...,\n",
      "        [ 1.7181e+03,  1.2125e+03, -7.4032e+04,  ...,  2.0425e+02,\n",
      "         -7.9524e+02,  4.0000e+00],\n",
      "        [ 1.7173e+03,  1.2262e+03, -7.3964e+04,  ...,  2.0405e+02,\n",
      "         -7.9518e+02,  4.0000e+00],\n",
      "        [ 1.7175e+03,  1.2235e+03, -7.3977e+04,  ...,  2.0409e+02,\n",
      "         -7.9519e+02,  4.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 设置要生成的数据数量  \n",
    "num_samples = 67291  \n",
    "target_category = 4\n",
    "# 生成新数据  \n",
    "new_data_u2r = generate_new_data(cvae, target_category, latent_dim, num_samples)  \n",
    "print(new_data_u2r.shape)\n",
    "\n",
    "#生成标签的一维Tensor\n",
    "labels = torch.full((num_samples,), target_category, dtype=torch.long)  \n",
    "# 为了拼接将标签Tensor扩展到与数据Tensor相同的维度  \n",
    "labels = labels.view(num_samples, 1)  \n",
    "labels = labels.to(device)\n",
    "# 沿着最后一个维度拼接数据和标签  \n",
    "new_data_u2r = torch.cat((new_data_u2r, labels), dim=-1)  \n",
    "  \n",
    "# 输出结果以验证  \n",
    "print(new_data_u2r)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d1f46f31-d798-4167-9cee-47a3d3e9b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 沿着第0维（通常是批次维度）拼接数据  \n",
    "combined_data = torch.cat((new_data_u2r, new_data_r2l,new_data_probe,new_data_dos), dim=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "63145106-7f4d-4ff0-87c7-16757dd4effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combined_data.cpu()\n",
    "combined_data = combined_data.numpy()\n",
    "# print(new_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "98e2c486-281a-4a62-8d55-240e041db0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "944a32fd-df5a-42fd-b808-278e3f7376e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./数据/KDDTrain+afterP.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "ad3d8d55-46b8-4580-8ec9-580ec39b605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
      "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
      "       ...\n",
      "       'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0',\n",
      "       'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH'],\n",
      "      dtype='object', length=124)\n"
     ]
    }
   ],
   "source": [
    "# 添加特征属性表头\n",
    "columns = train_df.columns\n",
    "print(columns)\n",
    "columns = columns.drop('attack_type')\n",
    "columns = columns.append(pd.Index(['attack_type']))\n",
    "combined_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6f421f99-6170-464e-857e-f4b0ea3b31a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1717.838623</td>\n",
       "      <td>1217.472656</td>\n",
       "      <td>-74007.390625</td>\n",
       "      <td>-912.247498</td>\n",
       "      <td>-222.200470</td>\n",
       "      <td>-343.736877</td>\n",
       "      <td>547.270264</td>\n",
       "      <td>1039.450806</td>\n",
       "      <td>894.286133</td>\n",
       "      <td>-505.291901</td>\n",
       "      <td>...</td>\n",
       "      <td>-635.063049</td>\n",
       "      <td>168.865021</td>\n",
       "      <td>179.309067</td>\n",
       "      <td>56.370983</td>\n",
       "      <td>1168.229614</td>\n",
       "      <td>19.720213</td>\n",
       "      <td>-28.625343</td>\n",
       "      <td>204.179352</td>\n",
       "      <td>-795.217224</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1717.476196</td>\n",
       "      <td>1224.123535</td>\n",
       "      <td>-73974.398438</td>\n",
       "      <td>-912.182251</td>\n",
       "      <td>-221.793182</td>\n",
       "      <td>-343.740295</td>\n",
       "      <td>547.227173</td>\n",
       "      <td>1039.229858</td>\n",
       "      <td>894.282349</td>\n",
       "      <td>-505.650940</td>\n",
       "      <td>...</td>\n",
       "      <td>-635.472351</td>\n",
       "      <td>168.968445</td>\n",
       "      <td>179.032990</td>\n",
       "      <td>56.753258</td>\n",
       "      <td>1168.811890</td>\n",
       "      <td>19.537388</td>\n",
       "      <td>-28.489155</td>\n",
       "      <td>204.081268</td>\n",
       "      <td>-795.189819</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1717.733887</td>\n",
       "      <td>1219.452881</td>\n",
       "      <td>-73997.625000</td>\n",
       "      <td>-912.228210</td>\n",
       "      <td>-222.078262</td>\n",
       "      <td>-343.737549</td>\n",
       "      <td>547.257202</td>\n",
       "      <td>1039.383667</td>\n",
       "      <td>894.286621</td>\n",
       "      <td>-505.400635</td>\n",
       "      <td>...</td>\n",
       "      <td>-635.186340</td>\n",
       "      <td>168.895981</td>\n",
       "      <td>179.225952</td>\n",
       "      <td>56.485699</td>\n",
       "      <td>1168.403809</td>\n",
       "      <td>19.665051</td>\n",
       "      <td>-28.584297</td>\n",
       "      <td>204.150208</td>\n",
       "      <td>-795.209290</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717.404907</td>\n",
       "      <td>1225.328735</td>\n",
       "      <td>-73968.476562</td>\n",
       "      <td>-912.170654</td>\n",
       "      <td>-221.720398</td>\n",
       "      <td>-343.741119</td>\n",
       "      <td>547.218811</td>\n",
       "      <td>1039.190308</td>\n",
       "      <td>894.281738</td>\n",
       "      <td>-505.717682</td>\n",
       "      <td>...</td>\n",
       "      <td>-635.545959</td>\n",
       "      <td>168.986923</td>\n",
       "      <td>178.982864</td>\n",
       "      <td>56.822346</td>\n",
       "      <td>1168.916626</td>\n",
       "      <td>19.505129</td>\n",
       "      <td>-28.464733</td>\n",
       "      <td>204.063797</td>\n",
       "      <td>-795.184387</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1716.874146</td>\n",
       "      <td>1235.025879</td>\n",
       "      <td>-73920.679688</td>\n",
       "      <td>-912.076721</td>\n",
       "      <td>-221.126297</td>\n",
       "      <td>-343.745605</td>\n",
       "      <td>547.148376</td>\n",
       "      <td>1038.867798</td>\n",
       "      <td>894.276001</td>\n",
       "      <td>-506.252075</td>\n",
       "      <td>...</td>\n",
       "      <td>-636.142639</td>\n",
       "      <td>169.139114</td>\n",
       "      <td>178.575546</td>\n",
       "      <td>57.384777</td>\n",
       "      <td>1169.767822</td>\n",
       "      <td>19.242712</td>\n",
       "      <td>-28.265415</td>\n",
       "      <td>203.922821</td>\n",
       "      <td>-795.145996</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210737</th>\n",
       "      <td>362.676697</td>\n",
       "      <td>66007.906250</td>\n",
       "      <td>19832.576172</td>\n",
       "      <td>-1987.499268</td>\n",
       "      <td>-434.537720</td>\n",
       "      <td>416.925385</td>\n",
       "      <td>-160.259979</td>\n",
       "      <td>38.416546</td>\n",
       "      <td>1998.897339</td>\n",
       "      <td>85.749146</td>\n",
       "      <td>...</td>\n",
       "      <td>273.860107</td>\n",
       "      <td>-358.166779</td>\n",
       "      <td>-73.463745</td>\n",
       "      <td>80.422165</td>\n",
       "      <td>-77.307655</td>\n",
       "      <td>-456.718719</td>\n",
       "      <td>472.619934</td>\n",
       "      <td>84.043076</td>\n",
       "      <td>-1418.917969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210738</th>\n",
       "      <td>362.832672</td>\n",
       "      <td>66004.140625</td>\n",
       "      <td>19814.478516</td>\n",
       "      <td>-1987.536987</td>\n",
       "      <td>-434.775604</td>\n",
       "      <td>416.927338</td>\n",
       "      <td>-160.222198</td>\n",
       "      <td>38.547977</td>\n",
       "      <td>1998.909424</td>\n",
       "      <td>85.952538</td>\n",
       "      <td>...</td>\n",
       "      <td>274.094727</td>\n",
       "      <td>-358.226288</td>\n",
       "      <td>-73.301628</td>\n",
       "      <td>80.198029</td>\n",
       "      <td>-77.653091</td>\n",
       "      <td>-456.616211</td>\n",
       "      <td>472.543427</td>\n",
       "      <td>84.095963</td>\n",
       "      <td>-1418.930420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210739</th>\n",
       "      <td>362.891846</td>\n",
       "      <td>66002.515625</td>\n",
       "      <td>19806.638672</td>\n",
       "      <td>-1987.553101</td>\n",
       "      <td>-434.880737</td>\n",
       "      <td>416.930878</td>\n",
       "      <td>-160.212708</td>\n",
       "      <td>38.611187</td>\n",
       "      <td>1998.916748</td>\n",
       "      <td>86.038834</td>\n",
       "      <td>...</td>\n",
       "      <td>274.193970</td>\n",
       "      <td>-358.254974</td>\n",
       "      <td>-73.230949</td>\n",
       "      <td>80.102028</td>\n",
       "      <td>-77.794952</td>\n",
       "      <td>-456.571838</td>\n",
       "      <td>472.511810</td>\n",
       "      <td>84.117393</td>\n",
       "      <td>-1418.936768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210740</th>\n",
       "      <td>362.342651</td>\n",
       "      <td>66012.648438</td>\n",
       "      <td>19856.451172</td>\n",
       "      <td>-1987.459106</td>\n",
       "      <td>-434.270996</td>\n",
       "      <td>416.925415</td>\n",
       "      <td>-160.269730</td>\n",
       "      <td>38.275959</td>\n",
       "      <td>1998.907104</td>\n",
       "      <td>85.511299</td>\n",
       "      <td>...</td>\n",
       "      <td>273.580627</td>\n",
       "      <td>-358.091339</td>\n",
       "      <td>-73.649513</td>\n",
       "      <td>80.679153</td>\n",
       "      <td>-76.916855</td>\n",
       "      <td>-456.843353</td>\n",
       "      <td>472.713867</td>\n",
       "      <td>83.986679</td>\n",
       "      <td>-1418.896362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210741</th>\n",
       "      <td>362.398163</td>\n",
       "      <td>66009.453125</td>\n",
       "      <td>19841.833984</td>\n",
       "      <td>-1987.492676</td>\n",
       "      <td>-434.496796</td>\n",
       "      <td>416.931274</td>\n",
       "      <td>-160.223740</td>\n",
       "      <td>38.412029</td>\n",
       "      <td>1998.925903</td>\n",
       "      <td>85.708908</td>\n",
       "      <td>...</td>\n",
       "      <td>273.793762</td>\n",
       "      <td>-358.148041</td>\n",
       "      <td>-73.496887</td>\n",
       "      <td>80.469872</td>\n",
       "      <td>-77.227066</td>\n",
       "      <td>-456.753052</td>\n",
       "      <td>472.644592</td>\n",
       "      <td>84.036156</td>\n",
       "      <td>-1418.905640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210742 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes         land  wrong_fragment  \\\n",
       "0       1717.838623   1217.472656 -74007.390625  -912.247498     -222.200470   \n",
       "1       1717.476196   1224.123535 -73974.398438  -912.182251     -221.793182   \n",
       "2       1717.733887   1219.452881 -73997.625000  -912.228210     -222.078262   \n",
       "3       1717.404907   1225.328735 -73968.476562  -912.170654     -221.720398   \n",
       "4       1716.874146   1235.025879 -73920.679688  -912.076721     -221.126297   \n",
       "...             ...           ...           ...          ...             ...   \n",
       "210737   362.676697  66007.906250  19832.576172 -1987.499268     -434.537720   \n",
       "210738   362.832672  66004.140625  19814.478516 -1987.536987     -434.775604   \n",
       "210739   362.891846  66002.515625  19806.638672 -1987.553101     -434.880737   \n",
       "210740   362.342651  66012.648438  19856.451172 -1987.459106     -434.270996   \n",
       "210741   362.398163  66009.453125  19841.833984 -1987.492676     -434.496796   \n",
       "\n",
       "            urgent         hot  num_failed_logins    logged_in  \\\n",
       "0      -343.736877  547.270264        1039.450806   894.286133   \n",
       "1      -343.740295  547.227173        1039.229858   894.282349   \n",
       "2      -343.737549  547.257202        1039.383667   894.286621   \n",
       "3      -343.741119  547.218811        1039.190308   894.281738   \n",
       "4      -343.745605  547.148376        1038.867798   894.276001   \n",
       "...            ...         ...                ...          ...   \n",
       "210737  416.925385 -160.259979          38.416546  1998.897339   \n",
       "210738  416.927338 -160.222198          38.547977  1998.909424   \n",
       "210739  416.930878 -160.212708          38.611187  1998.916748   \n",
       "210740  416.925415 -160.269730          38.275959  1998.907104   \n",
       "210741  416.931274 -160.223740          38.412029  1998.925903   \n",
       "\n",
       "        num_compromised  ...   flag_RSTO  flag_RSTOS0   flag_RSTR    flag_S0  \\\n",
       "0           -505.291901  ... -635.063049   168.865021  179.309067  56.370983   \n",
       "1           -505.650940  ... -635.472351   168.968445  179.032990  56.753258   \n",
       "2           -505.400635  ... -635.186340   168.895981  179.225952  56.485699   \n",
       "3           -505.717682  ... -635.545959   168.986923  178.982864  56.822346   \n",
       "4           -506.252075  ... -636.142639   169.139114  178.575546  57.384777   \n",
       "...                 ...  ...         ...          ...         ...        ...   \n",
       "210737        85.749146  ...  273.860107  -358.166779  -73.463745  80.422165   \n",
       "210738        85.952538  ...  274.094727  -358.226288  -73.301628  80.198029   \n",
       "210739        86.038834  ...  274.193970  -358.254974  -73.230949  80.102028   \n",
       "210740        85.511299  ...  273.580627  -358.091339  -73.649513  80.679153   \n",
       "210741        85.708908  ...  273.793762  -358.148041  -73.496887  80.469872   \n",
       "\n",
       "            flag_S1     flag_S2     flag_S3     flag_SF      flag_SH  \\\n",
       "0       1168.229614   19.720213  -28.625343  204.179352  -795.217224   \n",
       "1       1168.811890   19.537388  -28.489155  204.081268  -795.189819   \n",
       "2       1168.403809   19.665051  -28.584297  204.150208  -795.209290   \n",
       "3       1168.916626   19.505129  -28.464733  204.063797  -795.184387   \n",
       "4       1169.767822   19.242712  -28.265415  203.922821  -795.145996   \n",
       "...             ...         ...         ...         ...          ...   \n",
       "210737   -77.307655 -456.718719  472.619934   84.043076 -1418.917969   \n",
       "210738   -77.653091 -456.616211  472.543427   84.095963 -1418.930420   \n",
       "210739   -77.794952 -456.571838  472.511810   84.117393 -1418.936768   \n",
       "210740   -76.916855 -456.843353  472.713867   83.986679 -1418.896362   \n",
       "210741   -77.227066 -456.753052  472.644592   84.036156 -1418.905640   \n",
       "\n",
       "        attack_type  \n",
       "0                 4  \n",
       "1                 4  \n",
       "2                 4  \n",
       "3                 4  \n",
       "4                 4  \n",
       "...             ...  \n",
       "210737            0  \n",
       "210738            0  \n",
       "210739            0  \n",
       "210740            0  \n",
       "210741            0  \n",
       "\n",
       "[210742 rows x 124 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将最后一列的float类型转换为整数类型  \n",
    "combined_data['attack_type'] = combined_data['attack_type'].astype(int)  \n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "602b48b3-1b45-4289-8443-1f4046e350aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把attack_type的操作应用在原始数据集中\n",
    "train_df = train_df[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "47ceba5c-75d7-4c3d-a1ff-847a10c90f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_column = 'attack_type'\n",
    "  \n",
    "# 定义字符串标签到整数的映射  \n",
    "label_mapping = {'dos': 0, 'normal': 1, 'probe':2, 'r2l':3, 'u2r':4}  \n",
    "\n",
    "train_df[last_column] = train_df[last_column].replace(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5c70f97c-02df-4017-9836-714b767eef0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>0</td>\n",
       "      <td>2231</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0              0        491          0     0               0       0    0   \n",
       "1              0        146          0     0               0       0    0   \n",
       "2              0          0          0     0               0       0    0   \n",
       "3              0        232       8153     0               0       0    0   \n",
       "4              0        199        420     0               0       0    0   \n",
       "...          ...        ...        ...   ...             ...     ...  ...   \n",
       "125968         0          0          0     0               0       0    0   \n",
       "125969         8        105        145     0               0       0    0   \n",
       "125970         0       2231        384     0               0       0    0   \n",
       "125971         0          0          0     0               0       0    0   \n",
       "125972         0        151          0     0               0       0    0   \n",
       "\n",
       "        num_failed_logins  logged_in  num_compromised  ...  flag_RSTO  \\\n",
       "0                       0          0                0  ...          0   \n",
       "1                       0          0                0  ...          0   \n",
       "2                       0          0                0  ...          0   \n",
       "3                       0          1                0  ...          0   \n",
       "4                       0          1                0  ...          0   \n",
       "...                   ...        ...              ...  ...        ...   \n",
       "125968                  0          0                0  ...          0   \n",
       "125969                  0          0                0  ...          0   \n",
       "125970                  0          1                0  ...          0   \n",
       "125971                  0          0                0  ...          0   \n",
       "125972                  0          1                0  ...          0   \n",
       "\n",
       "        flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "0                 0          0        0        0        0        0        1   \n",
       "1                 0          0        0        0        0        0        1   \n",
       "2                 0          0        1        0        0        0        0   \n",
       "3                 0          0        0        0        0        0        1   \n",
       "4                 0          0        0        0        0        0        1   \n",
       "...             ...        ...      ...      ...      ...      ...      ...   \n",
       "125968            0          0        1        0        0        0        0   \n",
       "125969            0          0        0        0        0        0        1   \n",
       "125970            0          0        0        0        0        0        1   \n",
       "125971            0          0        1        0        0        0        0   \n",
       "125972            0          0        0        0        0        0        1   \n",
       "\n",
       "        flag_SH  attack_type  \n",
       "0             0            1  \n",
       "1             0            1  \n",
       "2             0            0  \n",
       "3             0            1  \n",
       "4             0            1  \n",
       "...         ...          ...  \n",
       "125968        0            0  \n",
       "125969        0            1  \n",
       "125970        0            1  \n",
       "125971        0            0  \n",
       "125972        0            1  \n",
       "\n",
       "[125973 rows x 124 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "875c3011-04dd-44a4-b375-35f7c73c45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用concat函数上下拼接  \n",
    "result = pd.concat([train_df, combined_data])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "1a8384a0-f7da-4d44-94c3-f329a820f380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "      <th>attack_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>491.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>8153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210737</th>\n",
       "      <td>362.676697</td>\n",
       "      <td>66007.906250</td>\n",
       "      <td>19832.576172</td>\n",
       "      <td>-1987.499268</td>\n",
       "      <td>-434.537720</td>\n",
       "      <td>416.925385</td>\n",
       "      <td>-160.259979</td>\n",
       "      <td>38.416546</td>\n",
       "      <td>1998.897339</td>\n",
       "      <td>85.749146</td>\n",
       "      <td>...</td>\n",
       "      <td>273.860107</td>\n",
       "      <td>-358.166779</td>\n",
       "      <td>-73.463745</td>\n",
       "      <td>80.422165</td>\n",
       "      <td>-77.307655</td>\n",
       "      <td>-456.718719</td>\n",
       "      <td>472.619934</td>\n",
       "      <td>84.043076</td>\n",
       "      <td>-1418.917969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210738</th>\n",
       "      <td>362.832672</td>\n",
       "      <td>66004.140625</td>\n",
       "      <td>19814.478516</td>\n",
       "      <td>-1987.536987</td>\n",
       "      <td>-434.775604</td>\n",
       "      <td>416.927338</td>\n",
       "      <td>-160.222198</td>\n",
       "      <td>38.547977</td>\n",
       "      <td>1998.909424</td>\n",
       "      <td>85.952538</td>\n",
       "      <td>...</td>\n",
       "      <td>274.094727</td>\n",
       "      <td>-358.226288</td>\n",
       "      <td>-73.301628</td>\n",
       "      <td>80.198029</td>\n",
       "      <td>-77.653091</td>\n",
       "      <td>-456.616211</td>\n",
       "      <td>472.543427</td>\n",
       "      <td>84.095963</td>\n",
       "      <td>-1418.930420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210739</th>\n",
       "      <td>362.891846</td>\n",
       "      <td>66002.515625</td>\n",
       "      <td>19806.638672</td>\n",
       "      <td>-1987.553101</td>\n",
       "      <td>-434.880737</td>\n",
       "      <td>416.930878</td>\n",
       "      <td>-160.212708</td>\n",
       "      <td>38.611187</td>\n",
       "      <td>1998.916748</td>\n",
       "      <td>86.038834</td>\n",
       "      <td>...</td>\n",
       "      <td>274.193970</td>\n",
       "      <td>-358.254974</td>\n",
       "      <td>-73.230949</td>\n",
       "      <td>80.102028</td>\n",
       "      <td>-77.794952</td>\n",
       "      <td>-456.571838</td>\n",
       "      <td>472.511810</td>\n",
       "      <td>84.117393</td>\n",
       "      <td>-1418.936768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210740</th>\n",
       "      <td>362.342651</td>\n",
       "      <td>66012.648438</td>\n",
       "      <td>19856.451172</td>\n",
       "      <td>-1987.459106</td>\n",
       "      <td>-434.270996</td>\n",
       "      <td>416.925415</td>\n",
       "      <td>-160.269730</td>\n",
       "      <td>38.275959</td>\n",
       "      <td>1998.907104</td>\n",
       "      <td>85.511299</td>\n",
       "      <td>...</td>\n",
       "      <td>273.580627</td>\n",
       "      <td>-358.091339</td>\n",
       "      <td>-73.649513</td>\n",
       "      <td>80.679153</td>\n",
       "      <td>-76.916855</td>\n",
       "      <td>-456.843353</td>\n",
       "      <td>472.713867</td>\n",
       "      <td>83.986679</td>\n",
       "      <td>-1418.896362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210741</th>\n",
       "      <td>362.398163</td>\n",
       "      <td>66009.453125</td>\n",
       "      <td>19841.833984</td>\n",
       "      <td>-1987.492676</td>\n",
       "      <td>-434.496796</td>\n",
       "      <td>416.931274</td>\n",
       "      <td>-160.223740</td>\n",
       "      <td>38.412029</td>\n",
       "      <td>1998.925903</td>\n",
       "      <td>85.708908</td>\n",
       "      <td>...</td>\n",
       "      <td>273.793762</td>\n",
       "      <td>-358.148041</td>\n",
       "      <td>-73.496887</td>\n",
       "      <td>80.469872</td>\n",
       "      <td>-77.227066</td>\n",
       "      <td>-456.753052</td>\n",
       "      <td>472.644592</td>\n",
       "      <td>84.036156</td>\n",
       "      <td>-1418.905640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336715 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration     src_bytes     dst_bytes         land  wrong_fragment  \\\n",
       "0         0.000000    491.000000      0.000000     0.000000        0.000000   \n",
       "1         0.000000    146.000000      0.000000     0.000000        0.000000   \n",
       "2         0.000000      0.000000      0.000000     0.000000        0.000000   \n",
       "3         0.000000    232.000000   8153.000000     0.000000        0.000000   \n",
       "4         0.000000    199.000000    420.000000     0.000000        0.000000   \n",
       "...            ...           ...           ...          ...             ...   \n",
       "210737  362.676697  66007.906250  19832.576172 -1987.499268     -434.537720   \n",
       "210738  362.832672  66004.140625  19814.478516 -1987.536987     -434.775604   \n",
       "210739  362.891846  66002.515625  19806.638672 -1987.553101     -434.880737   \n",
       "210740  362.342651  66012.648438  19856.451172 -1987.459106     -434.270996   \n",
       "210741  362.398163  66009.453125  19841.833984 -1987.492676     -434.496796   \n",
       "\n",
       "            urgent         hot  num_failed_logins    logged_in  \\\n",
       "0         0.000000    0.000000           0.000000     0.000000   \n",
       "1         0.000000    0.000000           0.000000     0.000000   \n",
       "2         0.000000    0.000000           0.000000     0.000000   \n",
       "3         0.000000    0.000000           0.000000     1.000000   \n",
       "4         0.000000    0.000000           0.000000     1.000000   \n",
       "...            ...         ...                ...          ...   \n",
       "210737  416.925385 -160.259979          38.416546  1998.897339   \n",
       "210738  416.927338 -160.222198          38.547977  1998.909424   \n",
       "210739  416.930878 -160.212708          38.611187  1998.916748   \n",
       "210740  416.925415 -160.269730          38.275959  1998.907104   \n",
       "210741  416.931274 -160.223740          38.412029  1998.925903   \n",
       "\n",
       "        num_compromised  ...   flag_RSTO  flag_RSTOS0  flag_RSTR    flag_S0  \\\n",
       "0              0.000000  ...    0.000000     0.000000   0.000000   0.000000   \n",
       "1              0.000000  ...    0.000000     0.000000   0.000000   0.000000   \n",
       "2              0.000000  ...    0.000000     0.000000   0.000000   1.000000   \n",
       "3              0.000000  ...    0.000000     0.000000   0.000000   0.000000   \n",
       "4              0.000000  ...    0.000000     0.000000   0.000000   0.000000   \n",
       "...                 ...  ...         ...          ...        ...        ...   \n",
       "210737        85.749146  ...  273.860107  -358.166779 -73.463745  80.422165   \n",
       "210738        85.952538  ...  274.094727  -358.226288 -73.301628  80.198029   \n",
       "210739        86.038834  ...  274.193970  -358.254974 -73.230949  80.102028   \n",
       "210740        85.511299  ...  273.580627  -358.091339 -73.649513  80.679153   \n",
       "210741        85.708908  ...  273.793762  -358.148041 -73.496887  80.469872   \n",
       "\n",
       "          flag_S1     flag_S2     flag_S3    flag_SF      flag_SH  attack_type  \n",
       "0        0.000000    0.000000    0.000000   1.000000     0.000000            1  \n",
       "1        0.000000    0.000000    0.000000   1.000000     0.000000            1  \n",
       "2        0.000000    0.000000    0.000000   0.000000     0.000000            0  \n",
       "3        0.000000    0.000000    0.000000   1.000000     0.000000            1  \n",
       "4        0.000000    0.000000    0.000000   1.000000     0.000000            1  \n",
       "...           ...         ...         ...        ...          ...          ...  \n",
       "210737 -77.307655 -456.718719  472.619934  84.043076 -1418.917969            0  \n",
       "210738 -77.653091 -456.616211  472.543427  84.095963 -1418.930420            0  \n",
       "210739 -77.794952 -456.571838  472.511810  84.117393 -1418.936768            0  \n",
       "210740 -76.916855 -456.843353  472.713867  83.986679 -1418.896362            0  \n",
       "210741 -77.227066 -456.753052  472.644592  84.036156 -1418.905640            0  \n",
       "\n",
       "[336715 rows x 124 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #这就是用CVAE数据平衡化处理得到的最终结果，实现各个类别平衡，每个类别有67343个样本，总共有336715个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ec9b78fd-fa3c-415b-be61-2d99dae03eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存新的数据集\n",
    "result.to_csv('KDDTrain_CVAE_CBN_100_20new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4335d7-bf06-4fd7-9668-95dc038ad74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50ca54-eb7a-412e-a12b-a378b1296e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d65170-4bc0-49e7-99cd-a208e9891df2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
